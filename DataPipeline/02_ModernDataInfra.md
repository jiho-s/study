## 02 최신 데이터 인프라

### 데이터 소스의 다양성

수십 개의 데이터 소스가 있으며, 이를 통해 분석 작업을 수행한다

#### 소스 시스템 소유권

분석 팀은 조직이 구축하고 소유한 소스 시스템과 타사 도구 및 공급업체에서 데이터를 수집 하는 것이 일반적이다.

#### 수집 인터페이스 및 데이터 구조

가장 먼저 알아봐야 할것은 소스 데이터를 얻는 방법과 형식이다

데이터에 대한 인터페이스가 무엇인지 살펴봐야한다

- 데이터베이스
- REST API
- Kafka
- csv 파일
- 데이터 웨어하우스, 데이터 레이크
- HDFS, Hbase

데이터 구조도 다양하다

- REST API 의 JSON
- MYSQL 의 잘 구성된 데이터
- MYSQL 컬럼내의 JSON
- 반정형화된 로그 데이터
- CSV
- Kafka의 스트림 출력

JSON과 같은 반정형 데이터가 점점 보편화 되고 있으며 속성-값 구조와 객체의 중첩 구조의 이점을 가지고 있다

#### 데이터 사이즈

분석 요구 사항과 대용량 데이터 모두에 핵심적인 데이터세트가 하나 이상 있다

#### 데이터 클렌징 작업과 유효성 검사

- 최악을 가정하고 최상을 기대하라
- 가장 적합한 시스템에서 데이터를 정리하고 검증하라
- 자주검증하라

#### 소스 시스템 지연 시간 및 데역폭

소스 시스템에서 대량의 데이터를 자주 추출하는 것은 최신 데이터 스택의 일반적인 사용 사례다,. 그러나 실제로 그렇게 하는 것은 어려운 일이다

### 클라우드 데이터 웨어하우스 및 데이터 레이크

#### 데이터 웨어하우스

사용자가 원하는 질문에 대답할 수 있는 데이터 분석활동을 지원하기 위해 서로 다른 시스템의 데이터가 모델링되어 저장되는 데이터 베이스이다

#### 데이터 레이크

다양한 유형뿐만 아니라 대량의 데이터가 포함될 가능성이 높다. 표준 데이터베이스 처럼 정형화된 데이터를 쿼리하는 데 최적화되지는 않았다



동일한 데이터 생태계에서 데이터 웨어하우스와 데이터 레이크 모두를 수용할 수 있는 공간이 있으며, 데이터 파이프라인이 둘 사이에서 데이터를 이동하는 경우가 많다

### 데이터 수집 도구

데이터 수집은 전통적으로 ETL 또는 ELT 프로세스의 추출 및 로드 단계다

### 데이터 변환 및 모델링 도구

파이프라인은 머신러닝, 분석 및 리포팅과 같은 새로운 목적을 위해 데이터를 변환하고 모델링하는 작업으로 구성된다.

#### 데이터 변환

데이터 변환은 ETL 또는 ELT 프로세스에서 T 에 해당하는 광범위한 용아다. 변환은 저장된 타임스탬프를 한 시간대에서 변환하는 것보다 집계되고 필터링된 여러 원본 열을 바탕으로 새 지표를 생성하는 더 복잡한 작업일 수도 있다

#### 데이터 모델링

보다 구체적인 데이터 변환 유형이다. 데이터 분석을 위해 데이터를 이해하고 최적화된 형식으로 정형화하고 정의한다.



데이터 수집과 마찬가지로 최신 데이터 인프라에서는 여러 가지 방법론과 도구가 있다.

### 워크플로 오케스트레이션 플랫폼

아파치 airflow, kubeflow pipeline 등

#### 방향성 비순환 그래프

**방향성**

하나의 작업 또는 여러개의 작업으로 시작하고 특정 작업으로 끝난다. 즉 모든 종속 작업이 완료되어야만 그 다음 작업이 실행된다

**비순환**

작업이 이전에 완료된 작업을 다음 작업으로 가리킬수 없다